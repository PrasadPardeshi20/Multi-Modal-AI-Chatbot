{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81190862",
   "metadata": {},
   "source": [
    "\n",
    "# Multiâ€‘Modal AI Chatbot â€” **Task 3 (NullClass Internship)**\n",
    "**Modes:**  \n",
    "- **Image â†’ Text** (Gemini 1.5)  \n",
    "- **Text â†’ Image** (OpenAI `gpt-image-1`)  \n",
    "- **Text â†’ Image** (Stability AI SDK)\n",
    "\n",
    "> **Note:** This notebook is intended as the required `.ipynb` deliverable. It demonstrates how to run the app, documents dependencies, and provides evaluation placeholders. API calls require valid keys and internet access in your environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d779a11",
   "metadata": {},
   "source": [
    "\n",
    "## Submission Requirements Mapping\n",
    "- âœ… `.ipynb` notebook (this file) â€” **included**\n",
    "- âœ… `requirements.txt` â€” **ensure in repo**\n",
    "- âœ… GUI (Streamlit) â€” **provided as `app.py`**\n",
    "- âœ… README with setup & screenshots â€” **add in repo**\n",
    "- â¬œ Evaluation notes (qualitative/quantitative) â€” **section provided below**\n",
    "- â¬œ Originality & disclaimer notes â€” **add in README/UI**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c41dce",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a248c81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run this once in a clean environment (uncomment as needed)\n",
    "# !pip install --upgrade pip\n",
    "# !pip install streamlit google-generativeai openai pillow requests stability-sdk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c838b0",
   "metadata": {},
   "source": [
    "## 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbcc85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import io\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "# Optional: only needed when running inside the app\n",
    "import streamlit as st  # noqa: F401\n",
    "import google.generativeai as genai  # noqa: F401\n",
    "import openai  # noqa: F401\n",
    "\n",
    "from stability_sdk import client  # noqa: F401\n",
    "import stability_sdk.interfaces.gooseai.generation.generation_pb2 as generation  # noqa: F401\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5f71d6",
   "metadata": {},
   "source": [
    "## 3. API Keys (Environment Variables Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d84ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set via environment variables or pass securely from a .env file\n",
    "# os.environ['GEMINI_API_KEY'] = '...'\n",
    "# os.environ['OPENAI_API_KEY'] = '...'\n",
    "# os.environ['STABILITY_API_KEY'] = '...'\n",
    "\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "STABILITY_API_KEY = os.getenv('STABILITY_API_KEY')\n",
    "\n",
    "print('Gemini Key set:', bool(GEMINI_API_KEY))\n",
    "print('OpenAI Key set:', bool(OPENAI_API_KEY))\n",
    "print('Stability Key set:', bool(STABILITY_API_KEY))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddb5a2e",
   "metadata": {},
   "source": [
    "## 4. Streamlit App Code (from `app.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33b76bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "app_code = r\"\"\"\n",
    "import streamlit as st\n",
    "import google.generativeai as genai\n",
    "import openai\n",
    "import io\n",
    "from PIL import Image\n",
    "import requests\n",
    "from stability_sdk import client\n",
    "import stability_sdk.interfaces.gooseai.generation.generation_pb2 as generation\n",
    "\n",
    "# -------------------- UI HEADER --------------------\n",
    "st.set_page_config(page_title=\"MultiModal AI Tool\", page_icon=\"ðŸ¤–\", layout=\"centered\")\n",
    "st.title(\"ðŸ–¼ï¸ MultiModal AI Tool\")\n",
    "st.write(\"Convert Images to Text (Gemini) & Text to Images (DALLÂ·E / Stability AI)\")\n",
    "\n",
    "# -------------------- API KEY INPUTS --------------------\n",
    "st.sidebar.header(\"ðŸ”‘ API Keys\")\n",
    "gemini_api_key = st.sidebar.text_input(\"Gemini API Key\", type=\"password\")\n",
    "openai_api_key = st.sidebar.text_input(\"OpenAI API Key (for DALLÂ·E)\", type=\"password\")\n",
    "stability_api_key = st.sidebar.text_input(\"Stability AI API Key\", type=\"password\")\n",
    "\n",
    "# -------------------- MODE SELECTION --------------------\n",
    "mode = st.radio(\"Select Mode\", [\"Image to Text (Gemini)\", \"Text to Image (DALLÂ·E)\", \"Text to Image (Stability AI)\"])\n",
    "\n",
    "# -------------------- GEMINI: IMAGE TO TEXT --------------------\n",
    "if mode == \"Image to Text (Gemini)\":\n",
    "    uploaded_image = st.file_uploader(\"Upload an Image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "    if uploaded_image and gemini_api_key:\n",
    "        image = Image.open(uploaded_image)\n",
    "        st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
    "\n",
    "        genai.configure(api_key=gemini_api_key)\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "        if st.button(\"Generate Description\"):\n",
    "            with st.spinner(\"Generating description...\"):\n",
    "                response = model.generate_content([image, \"Describe this image in detail.\"])\n",
    "                st.subheader(\"Image Description:\")\n",
    "                st.write(response.text)\n",
    "\n",
    "# -------------------- DALL-E: TEXT TO IMAGE --------------------\n",
    "elif mode == \"Text to Image (DALLÂ·E)\":\n",
    "    prompt = st.text_area(\"Enter your prompt\")\n",
    "    if prompt and openai_api_key:\n",
    "        openai.api_key = openai_api_key\n",
    "        if st.button(\"Generate Image (DALLÂ·E)\"):\n",
    "            with st.spinner(\"Generating image...\"):\n",
    "                try:\n",
    "                    result = openai.images.generate(\n",
    "                        model=\"gpt-image-1\",\n",
    "                        prompt=prompt,\n",
    "                        size=\"1024x1024\"\n",
    "                    )\n",
    "                    image_url = result.data[0].url\n",
    "                    st.image(image_url, caption=\"Generated Image (DALLÂ·E)\", use_column_width=True)\n",
    "                except Exception as e:\n",
    "                    st.error(f\"Error: {e}\")\n",
    "\n",
    "# -------------------- STABILITY AI: TEXT TO IMAGE --------------------\n",
    "elif mode == \"Text to Image (Stability AI)\":\n",
    "    prompt = st.text_area(\"Enter your prompt\")\n",
    "    if prompt and stability_api_key:\n",
    "        stability_api = client.StabilityInference(\n",
    "            key=stability_api_key,\n",
    "            verbose=True\n",
    "        )\n",
    "        if st.button(\"Generate Image (Stability AI)\"):\n",
    "            with st.spinner(\"Generating image...\"):\n",
    "                answers = stability_api.generate(\n",
    "                    prompt=prompt,\n",
    "                    steps=30,\n",
    "                    cfg_scale=8.0,\n",
    "                    width=512,\n",
    "                    height=512,\n",
    "                    samples=1,\n",
    "                    sampler=generation.SAMPLER_K_DPMPP_2M\n",
    "                )\n",
    "                for resp in answers:\n",
    "                    for artifact in resp.artifacts:\n",
    "                        if artifact.type == generation.ARTIFACT_IMAGE:\n",
    "                            img = Image.open(io.BytesIO(artifact.binary))\n",
    "                            st.image(img, caption=\"Generated Image (Stability AI)\", use_column_width=True)\n",
    "\"\"\"\n",
    "\n",
    "# Write/overwrite app.py next to this notebook if needed\n",
    "with open('app.py', 'w', encoding='utf-8') as f:\n",
    "    _ = f.write(app_code)\n",
    "\n",
    "print(\"app.py written successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4286d896",
   "metadata": {},
   "source": [
    "## 5. How to Run the App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d915c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# From a terminal in this folder:\n",
    "# streamlit run app.py\n",
    "#\n",
    "# Inside Jupyter (may not work in all environments):\n",
    "# !streamlit run app.py --server.headless true --server.port 8501\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671cb160",
   "metadata": {},
   "source": [
    "## 6. Optional: Minimal API Call Placeholders (Run only with valid keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dd8e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# GEMINI (Image â†’ Text) â€” Example (requires key and internet)\n",
    "# import google.generativeai as genai\n",
    "# genai.configure(api_key=GEMINI_API_KEY)\n",
    "# model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "# img = Image.open('your_image.jpg')\n",
    "# resp = model.generate_content([img, \"Describe this image in detail.\"])\n",
    "# print(resp.text)\n",
    "\n",
    "# OPENAI (Text â†’ Image)\n",
    "# import openai\n",
    "# openai.api_key = OPENAI_API_KEY\n",
    "# out = openai.images.generate(model='gpt-image-1', prompt='A futuristic city', size='512x512')\n",
    "# out.data[0].url\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd1fc0f",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Evaluation (Add Observations/Numbers)\n",
    "Suggested criteria (qualitative/quantitative):\n",
    "- **Latency**: response time for each mode.\n",
    "- **Relevance/Coherence**: human judgment (1â€“5 scale) for 10 prompts/images.\n",
    "- **Image Quality** (for generation): rate visual appeal & prompt alignment.\n",
    "- **Failure Handling**: error messages when keys missing or API limit exceeded.\n",
    "\n",
    "> Create a small table of 10 test cases and record scores per mode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4043f6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example evaluation table scaffold (fill manually after running real tests)\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'case_id': range(1, 6),\n",
    "    'mode': ['Image->Text', 'Image->Text', 'Text->Image(OpenAI)', 'Text->Image(Stability)', 'Text->Image(OpenAI)'],\n",
    "    'prompt_or_image': ['sample1.jpg', 'sample2.jpg', 'A cozy cabin', 'A neon dragon', 'A robot in a garden'],\n",
    "    'latency_sec': [None]*5,\n",
    "    'relevance_score_1to5': [None]*5,\n",
    "    'notes': ['']*5\n",
    "})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94709976",
   "metadata": {},
   "source": [
    "\n",
    "## 8. Ethical & Usage Notes\n",
    "- Outputs are **AI-generated** and may be inaccurate. Verify before use in critical contexts.\n",
    "- Respect content policies and copyright for generated/processed media.\n",
    "- Add attribution where required by API providers.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
